---
title: Translate viral load and PCR efficiency to test sensitivity at different dilutions
---

The RT-qPCR process leads to an exponential growth phase of the viral load, such that after some number of cycles $n$, the viral load $R_n$ will be a function of the efficiency of the reaction $E$, the dilution factor and the starting viral load in the sample $R_0$:

$$
R_n = \frac{R_0}{D}(1 + E)^n
$$

Let the probability of a positive case being detected be 0.98 for an undiluted sample, and 0.8 for a 10x diluted sample. Allow up to $C_T = 35$ cycles to reach some fluourescence detection threshold $R_{C_T}. Let $R_0$ be distributed in the population such that

$$
R_0 \sim 10^{U(0, 3)}
$$

and assume that efficiency is some distribution between 0.65 and 0.9 e.g.

$$
E ~ \sim Beta(\alpha, \beta) \times (0.9 - 0.65) + 0.65
$$

We need to find some distributions of $R_0$ and $E$ that will result in a sensitivity of 0.98 at $D=1$ and 0.8 at $D=0.8$

Simulate some values of $E$ and $R_0$

```{r}
set.seed(12345)
library(scales)
library(dplyr)
n <- 10000
R0 <- 10^runif(n, 0, 3)
E <- rbeta(n, 2, 5) %>% rescale(., to=c(0.65, 0.9))
hist(R0)
hist(E)
```

Calculate the $R_{C_T}$ values for different dilutions

```{r}
R35_1 <- R0 * (1 + E)^35
R35_10 <- R0/10 * (1 + E)^35
R35_30 <- R0/30 * (1 + E)^35
```

Are the sensitivities at the different dilutions concordant?

```{r}
(quantile(log(R35_1), 0.02) - quantile(log(R35_10), 0.2))^2
```

Quite similar. What sort of dilution curve does this give us?

```{r}
D <- seq(1,30)
Rct <- mean(c(
	quantile(log(R35_1), 0.02), 
	quantile(log(R35_10), 0.2)
))
dat <- tibble(
	D=D, 
	sensitivity=sapply(D, function(x) 
	{
		sum(log(R0/x * (1 + E)^35) > Rct)/n
	})
)
plot(sensitivity ~ D, dat)
```

Use optimisation to find parameters that will give concordant sensitivities at D = 1 and 10


```{r}
fn <- function(param, R0)
{
	n <- length(R0)
	E <- rbeta(n, param[1], param[2]) * (0.9-0.65) + 0.65
	R35_1 <- R0 * (1 + E)^35
	R35_10 <- R0/10 * (1 + E)^35
	q1 <- quantile(log(R35_1), 0.02, na.rm=TRUE)
	q10 <- quantile(log(R35_10), 0.2, na.rm=TRUE)
	return((q1 - q10)^2)
}
fn(c(2,5), R0)

n <- 100000
R0 <- 10^runif(n, 0, 3)
o <- optim(par = c(2, 5), fn=fn, R0=R0)
o
```

Now that we have parameter values for the distribution of $E$ we can generate the dilution curve

```{r}
D <- seq(1,100)
E <- rbeta(n, o$par[1], o$par[2]) * (0.9-0.65) + 0.65
Rct <- quantile(log(R0 * (1 + E)^35), 0.02)
dat <- tibble(
	D=D, 
	sensitivity=sapply(D, function(x) 
	{
		sum(log(R0/x * (1 + E)^35) > Rct)/n
	})
)
plot(sensitivity ~ D, dat)
```

## Using the viral load model to generate R0

Generate viral loads in large sample of individuals to obtain distribution according to the overall model

```{r}
source("../scripts/functions.r")
load("../data/circles.rdata")
ids <- do.call(rbind, lapply(1:30, function(i) ids))

sim <- expand.grid(
	# infection characteristics
	prevalence = c(1),
	spread = 3,
	containment = "high",

	# pooling characteristic
	pool_size = 2,
	random_pooling = TRUE,

	# costs
	cost_samplingkit = 2,
	cost_test = 25,
	replicates = 1
)
sim$f0 <- 14 # number of days of viral load
sim$f1 <- 0 # mean of lognormal for viral load distribution
sim$f2 <- 0.8 # sd of lognormal for viral load distribution
sim$g0 <- 0.3 # beta shape 1
sim$g1 <- 1 # beta shape 2
sim$g2 <- 3 # multiplier for beta distribution
sim$Emin <- 0.1 # Minimum PCR efficiency
sim$Emax <- 0.95 # Maximum PCR efficiency
sim$Ct <- 35 # Number cycles for detection
sim$fp <- 0.005 # Testing false positive rate (per test)

a <- cumulative_viral_load(sim$f0, sim$f1, sim$f2)
ids <- simulate_viral_load(ids, sim$f0, sim$f1, sim$f2, sim$g0, sim$g1, sim$g2, a)
hist(ids$vl, breaks=100)
hist(log(ids$vl), breaks=100)
hist(R0, breaks=100)
hist(log(R0), breaks=100)
```

Use the viral load as the R0 in the reaction. What test efficiency is required to obtain the calibration curves being observed.

```{r}
fn <- function(param, R0)
{
	n <- length(R0)
	E <- rbeta(n, param[1], param[2]) * (sim$Emax-sim$Emin) + sim$Emin
	R35_1 <- R0 * (1 + E)^sim$Ct
	R35_10 <- R0/10 * (1 + E)^sim$Ct
	q1 <- quantile(log(R35_1), 0.02, na.rm=TRUE)
	q10 <- quantile(log(R35_10), 0.2, na.rm=TRUE)
	return((q1 - q10)^2)
}
# fn(c(2,5), ids$vl)
# fn(c(2,7), ids$vl)

(efficiency_params <- optim(par = c(1, 1), fn=fn, R0=ids$vl, control=list(maxit=1000)))
```

Notes:

1. Need to increase the number of rows in `ids` to overcome the sampling error in sampling E during the optimisation procedure
2. Ideally would limit E to 0.65-0.9, but it seems like that won't fit. Relaxing that allows much smaller efficiencies which allows fit.
3. Re-running multiple times gives consistent estimates of E parameters

Plot the distribution of the efficiency

```{r}
D <- seq(1,100)
E <- rbeta(nrow(ids), efficiency_params$par[1], efficiency_params$par[2]) * (sim$Emax-sim$Emin) + sim$Emin
hist(E)

```

Plot the sensitivity change due to dilution

```{r}
Rct <- quantile(log(ids$vl * (1 + E)^sim$Ct), 0.02)
dat <- tibble(
	D=D, 
	sensitivity=sapply(D, function(x) 
	{
		sum(log(ids$vl/x * (1 + E)^sim$Ct) > Rct)/nrow(ids)
	})
)
plot(sensitivity ~ D, dat)
```

Save the parameter values for the model

```{r}
save(efficiency_params, Rct, file="../data/efficiency_params.rdata")
```

